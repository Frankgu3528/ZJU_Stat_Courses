统计学习导论-无监督学习
========================================================

# 主成分分析

- 用较少的变量代表较多的变量，方便可视化与理解数据
- 第一主成分$Z_1 = \phi_{11} X_1 + \phi_{21}X_2 + ... + \phi_{p1} X_p$ 方差最大， 正则化后有$\sum_{j = 1}^p \phi_{j1}^2 = 1$，则$\phi$为变量在第一主成分上的载荷
- 求解上第一主成分最大化$\frac{1}{n} \sum_{i = 1}^{n} z_{i1}^2$ 求解载荷值，$z_{ni}$是第一个样本在第一个主成分上的得分
- 载荷表示变量重要程度，得分表示样本重要程度
- 第二主成分与第一主成分正交求解
- biplot 同时表示载荷与得分，载荷向量接近表示有相关性，方向不一表示相关性弱，变量在主成分得分差异表示其状态
- 第一个主成分表示在p维空间里距离n个观察最近的超平面，因此具备代表性
- 取M个主成分可代表所有数据$x_{ij} \approx  \sum_{m = 1}^M z_{im} \phi_{jm}$
- 变量单位要统一，已经统一就不要标准化了
- 主成分是唯一的，符号可能有变化，载荷与得分值也唯一
- 主成分的重要性通过方差解释比例(PVE)来衡量，用碎石图来可视化$$\frac{\sum_{i = 1}^n (\sum_{j =1}^p \phi_{jm} x_{ij})^2}{\sum_{j =1}^p x_{ij}^2}$$
- 寻找碎石图的肘部来确定选取主成分的个数，方法不固定
- 可用来进行M小于p的主成分回归

# 聚类方法

- 寻找子分类或簇的方法，从异质性寻找同质性

## k均值聚类

- 子类中方差小，子类间方差大
- 事先指定子类个数
- 最小化所有K个平均欧式距离$W(C_k) = \frac{1}{|C_k|} \sum_{i,i' \in C_k} \sum_{j = 1}^{p} (x_{ij} - x_{i'j})^2$
- 先对所有样本随机分类，然后每种分类取中心，选取里中心距离最近的点重新分类，重新计算中心，迭代得到聚类结果

## 分层聚类

- 不需要指定先前聚类数，形成冰柱图
- 冰柱图要垂直分层解释，水平解释容易出现误导- 修剪冰柱图可给出聚类数
- 计算所有样本间距离，越相近就融合为一类，重新计算距离，反复这一过程
- 计算两者间相似度是很关键的，不同场景应用不同算法
- 变量的标准化处理上也很重要，考虑实际场景